{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lzwv_C0Nawbj",
        "outputId": "d83790f6-dd0d-4a6a-9f85-6c643f9ee0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.180-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.6-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.8.3)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.9)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.180-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.2.6-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, python-dotenv, pi-heif, opencv-python-headless, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, roboflow, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed filetype-1.2.0 idna-3.7 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 python-dotenv-1.1.1 roboflow-1.2.6 ultralytics-8.3.180 ultralytics-thop-2.0.15\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-1.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (25.0)\n",
            "Collecting choreographer>=1.0.5 (from kaleido)\n",
            "  Downloading choreographer-1.0.9-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting logistro>=1.0.8 (from kaleido)\n",
            "  Downloading logistro-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.11.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.27.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.10.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading kaleido-1.0.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading choreographer-1.0.9-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logistro-1.1.0-py3-none-any.whl (7.9 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: logistro, jedi, choreographer, kaleido\n",
            "Successfully installed choreographer-1.0.9 jedi-0.19.2 kaleido-1.0.0 logistro-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "site"
                ]
              },
              "id": "91acfa85c196453bbb1a478e83e3e823"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All dependencies installed successfully!\n",
            " Libraries imported and ready to use!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics roboflow opencv-python-headless matplotlib seaborn pandas numpy Pillow\n",
        "!pip install plotly kaleido scikit-learn ipywidgets\n",
        "\n",
        "# Import essential libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import json\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\" All dependencies installed successfully!\")\n",
        "print(\" Libraries imported and ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import YOLOv8 and other ML libraries\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from google.colab import files, drive\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Check GPU availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"  Using device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"  GPU not available. Training will be slower on CPU.\")\n",
        "\n",
        "print(\"\\n YOLOv8 and ML libraries ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z0NkQXXa9KV",
        "outputId": "31106bb4-9e31-45cc-80a6-a6721d609715"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Using device: cuda\n",
            "   GPU: Tesla T4\n",
            "   Memory: 15.8 GB\n",
            "\n",
            " YOLOv8 and ML libraries ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create project directories\n",
        "project_dir = Path('/content/asl_project')\n",
        "project_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Directory structure\n",
        "dirs = {\n",
        "    'datasets': project_dir / 'datasets',\n",
        "    'models': project_dir / 'models',\n",
        "    'results': project_dir / 'results',\n",
        "    'visualizations': project_dir / 'visualizations',\n",
        "    'predictions': project_dir / 'predictions'\n",
        "}\n",
        "\n",
        "for dir_path in dirs.values():\n",
        "    dir_path.mkdir(exist_ok=True)\n",
        "\n",
        "print(\" Project structure created:\")\n",
        "for name, path in dirs.items():\n",
        "    print(f\"   {name}: {path}\")\n",
        "\n",
        "os.chdir(project_dir)\n",
        "print(f\"\\n Working directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5qHqrbmbCAZ",
        "outputId": "1aa3a751-ced9-40fd-c427-11f105d044d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Project structure created:\n",
            "   datasets: /content/asl_project/datasets\n",
            "   models: /content/asl_project/models\n",
            "   results: /content/asl_project/results\n",
            "   visualizations: /content/asl_project/visualizations\n",
            "   predictions: /content/asl_project/predictions\n",
            "\n",
            " Working directory: /content/asl_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download comprehensive ASL datasets from Roboflow\n",
        "print(\" Downloading ASL datasets...\")\n",
        "\n",
        "# Initialize Roboflow Access\n",
        "rf = Roboflow(\"k2qq61C8Fe7H3IDfG3Gj\")\n",
        "\n",
        "# Download ASL Alphabet dataset\n",
        "print(\"\\n Downloading ASL Alphabet dataset...\")\n",
        "try:\n",
        "    alphabet_project = rf.workspace(\"david-lee-d0rhs\").project(\"american-sign-language-letters\")\n",
        "    alphabet_dataset = alphabet_project.version(6).download(\"yolov8\", location=\"./datasets/asl_alphabet\")\n",
        "    print(\" ASL Alphabet dataset downloaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"  Alphabet dataset error: {e}\")\n",
        "    print(\"   Trying alternative source...\")\n",
        "\n",
        "# Downloading ASL Numbers dataset\n",
        "print(\"\\n Downloading ASL Numbers dataset...\")\n",
        "try:\n",
        "    numbers_project = rf.workspace(\"roboflow-58fyf\").project(\"asl-numbers\")\n",
        "    numbers_dataset = numbers_project.version(1).download(\"yolov8\", location=\"./datasets/asl_numbers\")\n",
        "    print(\" ASL Numbers dataset downloaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"  Numbers dataset error: {e}\")\n",
        "    print(\"   Trying alternative source...\")\n",
        "\n",
        "# Backup Plan: Download from alternative sources if Roboflow fails\n",
        "print(\"\\n Checking for backup datasets...\")\n",
        "if not (project_dir / 'datasets' / 'asl_alphabet').exists():\n",
        "    print(\" Downloading backup ASL alphabet dataset...\")\n",
        "    !wget -O asl_alphabet.zip https://github.com/grassknoted/ASL-Alphabet/archive/master.zip\n",
        "    !unzip -q asl_alphabet.zip -d ./datasets/\n",
        "    print(\" Backup alphabet dataset ready!\")\n",
        "\n",
        "print(\"\\n Dataset download completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQjq8OrwbEqa",
        "outputId": "8fd7f127-25ab-4209-937d-4bf9ca4f8e0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading ASL datasets...\n",
            "\n",
            " Downloading ASL Alphabet dataset...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in ./datasets/asl_alphabet to yolov8:: 100%|██████████| 147097/147097 [00:05<00:00, 27858.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ./datasets/asl_alphabet in yolov8:: 100%|██████████| 1452/1452 [00:00<00:00, 1962.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ASL Alphabet dataset downloaded successfully!\n",
            "\n",
            " Downloading ASL Numbers dataset...\n",
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rloading Roboflow project...\n",
            "  Numbers dataset error: Version number 1 is not found.\n",
            "   Trying alternative source...\n",
            "\n",
            " Checking for backup datasets...\n",
            "\n",
            " Dataset download completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create unified dataset structure for YOLOv8\n",
        "import shutil\n",
        "import yaml\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "print(\" Preparing unified ASL dataset...\")\n",
        "\n",
        "# Define all ASL classes (36 total)\n",
        "asl_classes = {\n",
        "    # Alphabet A-Z\n",
        "    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,\n",
        "    'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16,\n",
        "    'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25,\n",
        "    # Numbers 0-9\n",
        "    '0': 26, '1': 27, '2': 28, '3': 29, '4': 30, '5': 31, '6': 32, '7': 33, '8': 34, '9': 35\n",
        "}\n",
        "\n",
        "# Create unified dataset directory\n",
        "unified_dir = project_dir / 'datasets' / 'asl_unified'\n",
        "unified_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    (unified_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    (unified_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Function to convert and copy dataset\n",
        "def process_dataset(source_dir, dataset_name, class_mapping=None):\n",
        "    \"\"\"Process and integrate dataset into unified structure\"\"\"\n",
        "    print(f\"\\n   Processing {dataset_name}...\")\n",
        "\n",
        "    if not source_dir.exists():\n",
        "        return 0\n",
        "\n",
        "    files_processed = 0\n",
        "\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        split_name = 'val' if split == 'valid' else split\n",
        "\n",
        "        source_images = source_dir / split / 'images'\n",
        "        source_labels = source_dir / split / 'labels'\n",
        "\n",
        "        if source_images.exists():\n",
        "            # Copy images\n",
        "            for img_file in source_images.glob('*'):\n",
        "                if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                    dest_img = unified_dir / split_name / 'images' / f\"{dataset_name}_{img_file.name}\"\n",
        "                    shutil.copy2(img_file, dest_img)\n",
        "\n",
        "                    # Copy corresponding label\n",
        "                    label_file = source_labels / f\"{img_file.stem}.txt\"\n",
        "                    if label_file.exists():\n",
        "                        dest_label = unified_dir / split_name / 'labels' / f\"{dataset_name}_{img_file.stem}.txt\"\n",
        "\n",
        "                        # Update class IDs if mapping provided\n",
        "                        if class_mapping:\n",
        "                            with open(label_file, 'r') as f:\n",
        "                                lines = f.readlines()\n",
        "\n",
        "                            with open(dest_label, 'w') as f:\n",
        "                                for line in lines:\n",
        "                                    parts = line.strip().split()\n",
        "                                    if parts:\n",
        "                                        old_class = int(parts[0])\n",
        "                                        if old_class in class_mapping:\n",
        "                                            parts[0] = str(class_mapping[old_class])\n",
        "                                            f.write(' '.join(parts) + '\\n')\n",
        "                        else:\n",
        "                            shutil.copy2(label_file, dest_label)\n",
        "\n",
        "                    files_processed += 1\n",
        "\n",
        "    return files_processed\n",
        "\n",
        "# Process available datasets\n",
        "total_files = 0\n",
        "\n",
        "# Process alphabet dataset\n",
        "alphabet_dir = project_dir / 'datasets' / 'asl_alphabet'\n",
        "total_files += process_dataset(alphabet_dir, 'alphabet')\n",
        "\n",
        "# Process numbers dataset\n",
        "numbers_dir = project_dir / 'datasets' / 'asl_numbers'\n",
        "total_files += process_dataset(numbers_dir, 'numbers')\n",
        "\n",
        "print(f\"\\n Unified dataset created with {total_files} files!\")\n",
        "\n",
        "# Create YAML configuration for YOLOv8\n",
        "yaml_config = {\n",
        "    'path': str(unified_dir),\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 36,  # number of classes\n",
        "    'names': [k for k, v in sorted(asl_classes.items(), key=lambda x: x[1])]\n",
        "}\n",
        "\n",
        "yaml_path = unified_dir / 'asl_config.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(yaml_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\" YOLOv8 config saved: {yaml_path}\")\n",
        "print(f\" Classes configured: {len(asl_classes)} total\")\n",
        "print(f\"   Alphabet: A-Z (26 classes)\")\n",
        "print(f\"   Numbers: 0-9 (10 classes)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii3_7XWbbIvO",
        "outputId": "f36a2cd6-b002-440b-b1db-8fef1181162b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Preparing unified ASL dataset...\n",
            "\n",
            "   Processing alphabet...\n",
            "\n",
            "   Processing numbers...\n",
            "     numbers not found, skipping...\n",
            "\n",
            " Unified dataset created with 720 files!\n",
            " YOLOv8 config saved: /content/asl_project/datasets/asl_unified/asl_config.yaml\n",
            " Classes configured: 36 total\n",
            "   Alphabet: A-Z (26 classes)\n",
            "   Numbers: 0-9 (10 classes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the unified dataset\n",
        "def analyze_dataset(dataset_path):\n",
        "    \"\"\"Analyze dataset composition and create visualizations\"\"\"\n",
        "\n",
        "    print(\" Analyzing ASL dataset composition...\")\n",
        "\n",
        "    splits_data = {}\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_dir = dataset_path / split\n",
        "\n",
        "        if split_dir.exists():\n",
        "            images = list((split_dir / 'images').glob('*'))\n",
        "            labels = list((split_dir / 'labels').glob('*'))\n",
        "\n",
        "            # Count classes in this split\n",
        "            class_counts = defaultdict(int)\n",
        "            total_annotations = 0\n",
        "\n",
        "            for label_file in labels:\n",
        "                with open(label_file, 'r') as f:\n",
        "                    for line in f:\n",
        "                        class_id = int(line.strip().split()[0])\n",
        "                        class_counts[class_id] += 1\n",
        "                        total_annotations += 1\n",
        "\n",
        "            splits_data[split] = {\n",
        "                'images': len(images),\n",
        "                'labels': len(labels),\n",
        "                'annotations': total_annotations,\n",
        "                'class_counts': dict(class_counts)\n",
        "            }\n",
        "\n",
        "    return splits_data\n",
        "\n",
        "# Analyze dataset\n",
        "analysis = analyze_dataset(unified_dir)\n",
        "\n",
        "# Create comprehensive visualizations\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=[\n",
        "        'Dataset Split Distribution',\n",
        "        'Images vs Labels',\n",
        "        'Class Distribution (Training Set)',\n",
        "        'Total Annotations by Split'\n",
        "    ],\n",
        "    specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
        "           [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "# 1. Dataset split distribution (pie chart)\n",
        "splits = list(analysis.keys())\n",
        "split_counts = [analysis[split]['images'] for split in splits]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Pie(labels=splits, values=split_counts, name=\"Split Distribution\"),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# 2. Images vs Labels comparison\n",
        "images_count = [analysis[split]['images'] for split in splits]\n",
        "labels_count = [analysis[split]['labels'] for split in splits]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(x=splits, y=images_count, name='Images', marker_color='lightblue'),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Bar(x=splits, y=labels_count, name='Labels', marker_color='lightcoral'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# 3. Class distribution in training set\n",
        "if 'train' in analysis and analysis['train']['class_counts']:\n",
        "    class_names = [yaml_config['names'][i] for i in sorted(analysis['train']['class_counts'].keys())]\n",
        "    class_counts = [analysis['train']['class_counts'][i] for i in sorted(analysis['train']['class_counts'].keys())]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=class_names, y=class_counts, name='Training Classes', marker_color='lightgreen'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# 4. Total annotations by split\n",
        "annotation_counts = [analysis[split]['annotations'] for split in splits]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(x=splits, y=annotation_counts, name='Annotations', marker_color='gold'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text=\"ASL Dataset Analysis Dashboard\",\n",
        "    showlegend=True,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\n Dataset Summary:\")\n",
        "total_images = sum(analysis[split]['images'] for split in analysis)\n",
        "total_annotations = sum(analysis[split]['annotations'] for split in analysis)\n",
        "\n",
        "print(f\"   Total Images: {total_images:,}\")\n",
        "print(f\"   Total Annotations: {total_annotations:,}\")\n",
        "print(f\"   Classes: {len(asl_classes)} (A-Z + 0-9)\")\n",
        "\n",
        "for split in analysis:\n",
        "    data = analysis[split]\n",
        "    print(f\"\\n   {split.upper()} Set:\")\n",
        "    print(f\"     Images: {data['images']:,}\")\n",
        "    print(f\"     Labels: {data['labels']:,}\")\n",
        "    print(f\"     Annotations: {data['annotations']:,}\")\n",
        "\n",
        "    if data['annotations'] > 0:\n",
        "        avg_per_image = data['annotations'] / data['images'] if data['images'] > 0 else 0\n",
        "        print(f\"     Avg annotations/image: {avg_per_image:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P1PTrNHtbNae",
        "outputId": "7b20ca62-30bb-4959-8b34-57dd3b4bd723"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Analyzing ASL dataset composition...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"044494e1-7205-40af-85ba-b15fe64821bc\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"044494e1-7205-40af-85ba-b15fe64821bc\")) {                    Plotly.newPlot(                        \"044494e1-7205-40af-85ba-b15fe64821bc\",                        [{\"labels\":[\"train\",\"val\",\"test\"],\"name\":\"Split Distribution\",\"values\":[504,144,72],\"type\":\"pie\",\"domain\":{\"x\":[0.0,0.45],\"y\":[0.625,1.0]}},{\"marker\":{\"color\":\"lightblue\"},\"name\":\"Images\",\"x\":[\"train\",\"val\",\"test\"],\"y\":[504,144,72],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"lightcoral\"},\"name\":\"Labels\",\"x\":[\"train\",\"val\",\"test\"],\"y\":[504,144,72],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"lightgreen\"},\"name\":\"Training Classes\",\"x\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"],\"y\":[23,13,18,21,21,20,20,17,26,26,17,24,17,20,18,17,20,16,23,14,16,19,19,21,16,22],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"gold\"},\"name\":\"Annotations\",\"x\":[\"train\",\"val\",\"test\"],\"y\":[504,144,72],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.55,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Dataset Split Distribution\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Images vs Labels\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Class Distribution (Training Set)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total Annotations by Split\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"ASL Dataset Analysis Dashboard\"},\"showlegend\":true,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('044494e1-7205-40af-85ba-b15fe64821bc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset Summary:\n",
            "   Total Images: 720\n",
            "   Total Annotations: 720\n",
            "   Classes: 36 (A-Z + 0-9)\n",
            "\n",
            "   TRAIN Set:\n",
            "     Images: 504\n",
            "     Labels: 504\n",
            "     Annotations: 504\n",
            "     Avg annotations/image: 1.00\n",
            "\n",
            "   VAL Set:\n",
            "     Images: 144\n",
            "     Labels: 144\n",
            "     Annotations: 144\n",
            "     Avg annotations/image: 1.00\n",
            "\n",
            "   TEST Set:\n",
            "     Images: 72\n",
            "     Labels: 72\n",
            "     Annotations: 72\n",
            "     Avg annotations/image: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YOLOv8 model\n",
        "print(\" Initializing YOLOv8 model...\")\n",
        "\n",
        "# Use YOLOv8n (nano) for faster training, or YOLOv8s/m/l for better accuracy\n",
        "model_size = 'n'  # Options: n (nano), s (small), m (medium), l (large), x (extra large)\n",
        "model = YOLO(f'yolov8{model_size}.pt')  # Load pretrained model\n",
        "\n",
        "print(f\" YOLOv8{model_size} model loaded successfully!\")\n",
        "print(f\" Target classes: {len(asl_classes)} ASL signs\")\n",
        "\n",
        "# Training hyperparameters optimized for ASL detection\n",
        "training_config = {\n",
        "    'data': str(yaml_path),\n",
        "    'epochs': 100,  # Increased for better accuracy\n",
        "    'imgsz': 640,   # Image size\n",
        "    'batch': 16,    # Adjust based on GPU memory\n",
        "    'lr0': 0.01,    # Initial learning rate\n",
        "    'lrf': 0.1,     # Final learning rate factor\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3.0,\n",
        "    'warmup_momentum': 0.8,\n",
        "    'box': 0.05,    # Box loss gain\n",
        "    'cls': 0.5,     # Class loss gain\n",
        "    'dfl': 1.5,     # DFL loss gain\n",
        "    'pose': 12.0,   # Pose loss gain (unused)\n",
        "    'kobj': 1.0,    # Keypoint obj loss gain (unused)\n",
        "    'label_smoothing': 0.0,\n",
        "    'nbs': 64,      # Nominal batch size\n",
        "    'overlap_mask': True,\n",
        "    'mask_ratio': 4,\n",
        "    'dropout': 0.0,\n",
        "    'val': True,    # Validate during training\n",
        "    'save': True,   # Save checkpoints\n",
        "    'save_period': 10,  # Save every 10 epochs\n",
        "    'cache': False, # Cache images for faster training (disable if memory limited)\n",
        "    'device': device,\n",
        "    'workers': 8,   # Number of worker threads\n",
        "    'project': str(dirs['models']),\n",
        "    'name': 'asl_yolov8_training',\n",
        "    'exist_ok': True,\n",
        "    'pretrained': True,\n",
        "    'optimizer': 'auto',  # Auto-select optimizer\n",
        "    'verbose': True,\n",
        "    'seed': 42,     # For reproducibility\n",
        "    'deterministic': True,\n",
        "    'single_cls': False,\n",
        "    'rect': False,  # Rectangular training\n",
        "    'cos_lr': False,\n",
        "    'close_mosaic': 10,\n",
        "    'resume': False,\n",
        "    'amp': True,    # Automatic Mixed Precision\n",
        "    'fraction': 1.0,\n",
        "    'profile': False,\n",
        "    'freeze': None,\n",
        "}\n",
        "\n",
        "print(\"\\n  Training Configuration:\")\n",
        "for key, value in training_config.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\n Ready to start training!\")\n",
        "print(f\" Models will be saved to: {dirs['models']}\")\n",
        "print(f\" Training results will be in: {dirs['results']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ppe6DIbQoi",
        "outputId": "1754a9f4-b007-44f7-b2a5-697ad6300b97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Initializing YOLOv8 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100%|██████████| 6.25M/6.25M [00:00<00:00, 52.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " YOLOv8n model loaded successfully!\n",
            " Target classes: 36 ASL signs\n",
            "\n",
            "  Training Configuration:\n",
            "   data: /content/asl_project/datasets/asl_unified/asl_config.yaml\n",
            "   epochs: 100\n",
            "   imgsz: 640\n",
            "   batch: 16\n",
            "   lr0: 0.01\n",
            "   lrf: 0.1\n",
            "   momentum: 0.937\n",
            "   weight_decay: 0.0005\n",
            "   warmup_epochs: 3.0\n",
            "   warmup_momentum: 0.8\n",
            "   box: 0.05\n",
            "   cls: 0.5\n",
            "   dfl: 1.5\n",
            "   pose: 12.0\n",
            "   kobj: 1.0\n",
            "   label_smoothing: 0.0\n",
            "   nbs: 64\n",
            "   overlap_mask: True\n",
            "   mask_ratio: 4\n",
            "   dropout: 0.0\n",
            "   val: True\n",
            "   save: True\n",
            "   save_period: 10\n",
            "   cache: False\n",
            "   device: cuda\n",
            "   workers: 8\n",
            "   project: /content/asl_project/models\n",
            "   name: asl_yolov8_training\n",
            "   exist_ok: True\n",
            "   pretrained: True\n",
            "   optimizer: auto\n",
            "   verbose: True\n",
            "   seed: 42\n",
            "   deterministic: True\n",
            "   single_cls: False\n",
            "   rect: False\n",
            "   cos_lr: False\n",
            "   close_mosaic: 10\n",
            "   resume: False\n",
            "   amp: True\n",
            "   fraction: 1.0\n",
            "   profile: False\n",
            "   freeze: None\n",
            "\n",
            " Ready to start training!\n",
            " Models will be saved to: /content/asl_project/models\n",
            " Training results will be in: /content/asl_project/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training with progress monitoring\n",
        "print(\" Starting YOLOv8 training for ASL detection...\")\n",
        "print(\"  This will take 30-60 minutes depending on your GPU\")\n",
        "print(\" Training metrics will be displayed in real-time\\n\")\n",
        "\n",
        "try:\n",
        "    # Train the model\n",
        "    results = model.train(**training_config)\n",
        "\n",
        "    print(\"\\n Training completed successfully!\")\n",
        "    print(f\" Best model saved as: best.pt\")\n",
        "    print(f\" Training results saved to: {training_config['project']}/{training_config['name']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Training failed: {e}\")\n",
        "    print(\" Trying with reduced batch size...\")\n",
        "\n",
        "    # Retry with smaller batch size if memory issues\n",
        "    training_config['batch'] = 8\n",
        "    training_config['imgsz'] = 512\n",
        "\n",
        "    try:\n",
        "        results = model.train(**training_config)\n",
        "        print(\"\\n Training completed with reduced settings!\")\n",
        "    except Exception as e2:\n",
        "        print(f\" Training failed again: {e2}\")\n",
        "        print(\"  Please check your dataset and try again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLYU1EyWbTKA",
        "outputId": "0e272478-b9a3-406c-a580-b86d46cfced4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Starting YOLOv8 training for ASL detection...\n",
            "  This will take 30-60 minutes depending on your GPU\n",
            " Training metrics will be displayed in real-time\n",
            "\n",
            "WARNING ⚠️ 'label_smoothing' is deprecated and will be removed in in the future.\n",
            "Ultralytics 8.3.180 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=0.05, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/asl_project/datasets/asl_unified/asl_config.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=asl_yolov8_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/asl_project/models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/asl_project/models/asl_yolov8_training, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 14.1MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=36\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    758332  ultralytics.nn.modules.head.Detect           [36, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,017,868 parameters, 3,017,852 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:00<00:00, 67.0MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2554.9±1556.4 MB/s, size: 197.2 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/asl_project/datasets/asl_unified/train/labels... 504 images, 0 backgrounds, 0 corrupt: 100%|██████████| 504/504 [00:00<00:00, 2367.08it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/asl_project/datasets/asl_unified/train/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 961.1±965.9 MB/s, size: 197.2 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/asl_project/datasets/asl_unified/val/labels... 144 images, 0 backgrounds, 0 corrupt: 100%|██████████| 144/144 [00:00<00:00, 1690.22it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/asl_project/datasets/asl_unified/val/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/asl_project/models/asl_yolov8_training/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00025, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/asl_project/models/asl_yolov8_training\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      2.06G   0.006167      4.513      1.322         14        640: 100%|██████████| 32/32 [00:14<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144          0          0          0          0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      2.29G   0.005081      4.086      1.203         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144     0.0298      0.668     0.0986     0.0887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      2.31G   0.005071      3.683      1.197         20        640: 100%|██████████| 32/32 [00:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.453      0.275      0.219      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      2.33G   0.004957      3.313      1.203         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.419      0.364      0.385      0.331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      2.34G   0.005173      3.093      1.213         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.328      0.572      0.533      0.468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      2.36G   0.004955      2.874      1.184         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.481      0.597      0.581      0.516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      2.38G   0.004954      2.622      1.189         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.54      0.614      0.686      0.615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100       2.4G   0.004822      2.512      1.176         13        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.642      0.631       0.73      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      2.41G   0.004534      2.281      1.145         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.674      0.658      0.784      0.697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      2.43G   0.004444      2.206      1.128         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.743       0.71      0.802      0.703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      2.45G   0.004665      2.061      1.145         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.50it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.669      0.708      0.801      0.712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      2.46G   0.004384      1.959      1.116         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.795      0.691      0.842      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      2.48G   0.004216      1.887      1.106         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.76it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.646      0.788       0.83      0.754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100       2.5G   0.004349      1.833      1.088         21        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.84it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.755      0.778      0.877      0.798\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      2.52G   0.004285      1.758      1.096         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.91it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.799      0.793      0.863      0.792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      2.54G   0.004082      1.654      1.075         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.77      0.771       0.86      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      2.55G    0.00423      1.648      1.072         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.734      0.827      0.887      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      2.57G   0.004034      1.522      1.052         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.77      0.789      0.875        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      2.58G   0.003911      1.591      1.064         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.749      0.854      0.897      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100       2.6G    0.00368      1.436      1.027         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.801       0.85      0.896      0.825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      2.62G   0.003941      1.446      1.044         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.73it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.863      0.867      0.918      0.847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      2.63G   0.003831      1.449      1.057         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.63it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.803      0.842      0.899      0.827\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      2.65G   0.003652      1.304      1.017         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.804      0.823      0.908      0.832\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      2.67G    0.00399      1.382      1.063         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.894      0.824      0.906      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      2.69G   0.003787      1.375      1.039         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.03it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.843      0.853       0.93       0.86\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100       2.7G   0.003937      1.324      1.047         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.82it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.802       0.85      0.914      0.843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      2.72G   0.003883      1.309      1.046         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.24it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.855      0.852       0.92       0.85\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      2.74G    0.00384       1.26      1.035         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.87      0.856      0.938      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      2.75G    0.00378      1.253      1.035         21        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.97it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.848      0.842      0.929      0.861\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      2.77G   0.003819      1.234      1.032         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.838      0.836      0.932      0.863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      2.79G   0.003751       1.23      1.037         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.91      0.842      0.925      0.856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      2.81G   0.003408      1.148     0.9975         17        640: 100%|██████████| 32/32 [00:13<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.812      0.883      0.931      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      2.82G   0.003652      1.164      1.027         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.87it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.893      0.841      0.931      0.865\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      2.84G   0.003695      1.184      1.032         25        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.876      0.842      0.931      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      2.86G   0.003456      1.097     0.9988         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.834      0.877      0.935      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      2.87G   0.003478      1.103      1.007         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.89it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.887       0.86      0.942      0.884\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      2.89G   0.003529      1.094      1.002         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.912      0.845      0.952      0.894\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      2.91G   0.003582      1.095      1.021         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.22it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.886      0.855      0.944      0.873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      2.93G   0.003558      1.102      1.004         14        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.07it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.895      0.851      0.942      0.875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      2.94G   0.003421      1.064     0.9998         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.75it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.839      0.892      0.937       0.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      2.96G   0.003317      1.034     0.9908         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.17it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.945       0.87      0.952      0.884\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      2.98G   0.003546      1.026      1.004         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.907      0.838      0.952      0.893\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      2.99G   0.003476     0.9832     0.9946         14        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.906      0.875       0.95       0.89\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      3.01G   0.003443      1.016      1.008         24        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.95it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.837      0.879       0.93      0.864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      3.03G   0.003474     0.9826      1.002         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.82it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.902      0.863      0.941      0.881\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      3.05G   0.003334      1.003     0.9958         13        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.94it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.911      0.839      0.929       0.86\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      3.06G   0.003304     0.9618     0.9787         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.877      0.892      0.932      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      3.08G   0.003442     0.9467      1.009         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.10it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144       0.89      0.832       0.93      0.866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100       3.1G   0.003473      0.951      1.008         21        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.86it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.894      0.887      0.938      0.876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      3.11G   0.003288     0.9424     0.9858         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.11it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        144        144      0.873      0.877      0.942      0.883\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      3.13G   0.003478     0.9463      1.008         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.892      0.868      0.939      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      3.15G   0.003165      0.915     0.9841         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.894       0.88      0.946      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      3.16G   0.003314     0.9256     0.9851         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.884      0.911       0.96        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      3.18G    0.00338     0.9617      1.019         25        640: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.943      0.881      0.959      0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100       3.2G    0.00327     0.9107     0.9844         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.944      0.856      0.956        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      3.22G   0.003308     0.9183     0.9883         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144       0.94      0.892      0.958      0.901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      3.23G   0.003285     0.8643      0.985         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.942       0.86      0.955      0.889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      3.25G   0.003238     0.8663     0.9845         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.898      0.901      0.956      0.897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      3.27G   0.003121     0.8533     0.9832         13        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.917      0.878       0.96      0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      3.29G   0.003266     0.9001      0.987         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.911      0.902      0.955      0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100       3.3G   0.003164     0.8478     0.9786         14        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.908      0.891      0.966      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      3.32G   0.003072     0.8215     0.9674         14        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.933      0.851      0.958      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      3.34G   0.003151      0.841     0.9834         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.901      0.902       0.96      0.897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      3.35G   0.003212     0.8627     0.9998         15        640: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.934      0.861      0.962      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      3.37G   0.003168      0.823     0.9671         21        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.899      0.893      0.956      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      3.39G   0.003092     0.8183     0.9776         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.908      0.891      0.958      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      3.41G   0.003143     0.8479     0.9819         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.884      0.934      0.967      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      3.42G   0.003039     0.7918     0.9633         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.914      0.915      0.968      0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      3.44G   0.003049     0.7722     0.9746         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144       0.93      0.916      0.961      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      3.46G   0.003134     0.7948     0.9827         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.928      0.894       0.96      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      3.47G   0.003098     0.8017     0.9675         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.915      0.895      0.962      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      3.49G   0.003103     0.7986     0.9715         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.928      0.876      0.954        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      3.51G   0.003164     0.8045     0.9782         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.941      0.893      0.957      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      3.52G   0.002987     0.7638     0.9621         22        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.957      0.898       0.96      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      3.54G   0.003014     0.7717     0.9716         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.943      0.902      0.964      0.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      3.56G   0.003069     0.7596     0.9715         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.935      0.899      0.964      0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      3.58G   0.002931     0.7211      0.953         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.941      0.883      0.964      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      3.59G   0.003071     0.7426     0.9675         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.909      0.908      0.965      0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      3.61G   0.002944      0.733     0.9631         19        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144       0.91      0.908       0.96      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      3.63G   0.003024     0.7442     0.9806         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.944      0.878      0.968      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      3.65G   0.003009     0.7299     0.9674         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.936      0.886      0.964      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      3.66G    0.00291     0.7329     0.9637         15        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.938      0.882      0.959      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      3.68G   0.002911      0.699     0.9505         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.917      0.892      0.959        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100       3.7G   0.002987     0.7255      0.955         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.928      0.883      0.955      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      3.71G   0.002885     0.6826     0.9557         23        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.914      0.892      0.954      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      3.73G   0.002902     0.7034     0.9534         17        640: 100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.924      0.915      0.958      0.902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      3.75G   0.002899     0.6967     0.9698         18        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.918      0.908      0.945       0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      3.76G   0.002878     0.6897     0.9587         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.935      0.897      0.951      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      3.78G   0.002819     0.6677     0.9612         16        640: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.926      0.902      0.961      0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100       3.8G   0.003046      0.725     0.9611         20        640: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.945      0.881      0.956      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      3.81G   0.001882     0.7239     0.8502          8        640: 100%|██████████| 32/32 [00:15<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.893      0.893      0.954      0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100      3.83G   0.001885     0.7027     0.8471          8        640: 100%|██████████| 32/32 [00:13<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.901      0.903      0.954      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      3.85G   0.001797     0.6621     0.8435          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.924      0.901      0.955      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      3.87G   0.001828     0.6505      0.839          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144       0.92      0.903      0.953      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      3.88G   0.001848     0.6556     0.8594          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.909      0.913      0.961      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100       3.9G   0.001717     0.6371     0.8398          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.924      0.906      0.963      0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      3.92G   0.001755     0.6269     0.8451          8        640: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.912      0.912      0.967      0.912\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      3.94G   0.001721     0.6178     0.8368          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.908      0.914      0.967      0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100      3.95G   0.001731     0.6187     0.8403          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.926      0.899      0.965      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      3.97G   0.001747     0.6057     0.8452          8        640: 100%|██████████| 32/32 [00:12<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.927      0.894      0.964      0.917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "100 epochs completed in 0.425 hours.\n",
            "Optimizer stripped from /content/asl_project/models/asl_yolov8_training/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/asl_project/models/asl_yolov8_training/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/asl_project/models/asl_yolov8_training/weights/best.pt...\n",
            "Ultralytics 8.3.180 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,012,668 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        144        144      0.927      0.894      0.964      0.917\n",
            "                     A          5          5          1      0.679      0.995      0.932\n",
            "                     B          9          9          1      0.914      0.995       0.93\n",
            "                     C          3          3      0.942          1      0.995      0.913\n",
            "                     D          6          6      0.836          1      0.995      0.956\n",
            "                     E          4          4      0.974          1      0.995      0.995\n",
            "                     F          8          8      0.966          1      0.995      0.976\n",
            "                     G          5          5      0.961          1      0.995      0.941\n",
            "                     H          9          9      0.982          1      0.995      0.924\n",
            "                     I          2          2      0.881        0.5      0.524      0.524\n",
            "                     J          8          8      0.983          1      0.995      0.698\n",
            "                     K          6          6       0.84      0.833      0.972      0.972\n",
            "                     L          4          4      0.913          1      0.995       0.97\n",
            "                     M          8          8          1      0.801      0.995      0.928\n",
            "                     N          4          4      0.624          1      0.995       0.97\n",
            "                     O          7          7          1      0.885      0.995      0.945\n",
            "                     P          7          7          1      0.719      0.874      0.802\n",
            "                     Q          4          4      0.967          1      0.995       0.92\n",
            "                     R          7          7          1       0.91      0.995      0.995\n",
            "                     S          4          4      0.956          1      0.995      0.995\n",
            "                     T          6          6       0.77      0.667      0.833      0.806\n",
            "                     U          7          7      0.939          1      0.995      0.964\n",
            "                     V          5          5          1      0.604      0.995      0.956\n",
            "                     W          3          3      0.768          1      0.995      0.995\n",
            "                     X          1          1      0.851          1      0.995      0.995\n",
            "                     Y          8          8          1       0.73      0.971      0.886\n",
            "                     Z          4          4      0.954          1      0.995      0.954\n",
            "Speed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/asl_project/models/asl_yolov8_training\u001b[0m\n",
            "\n",
            " Training completed successfully!\n",
            " Best model saved as: best.pt\n",
            " Training results saved to: /content/asl_project/models/asl_yolov8_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best trained model\n",
        "print(\" Loading best trained model...\")\n",
        "\n",
        "try:\n",
        "    # Find the best model path\n",
        "    model_path = dirs['models'] / 'asl_yolov8_training' / 'weights' / 'best.pt'\n",
        "\n",
        "    if model_path.exists():\n",
        "        best_model = YOLO(str(model_path))\n",
        "        print(f\" Best model loaded from: {model_path}\")\n",
        "    else:\n",
        "        print(\" Best model not found, using last checkpoint...\")\n",
        "        model_path = dirs['models'] / 'asl_yolov8_training' / 'weights' / 'last.pt'\n",
        "        best_model = YOLO(str(model_path))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Error loading model: {e}\")\n",
        "    print(\"Using original model for evaluation...\")\n",
        "    best_model = model\n",
        "\n",
        "# Model information\n",
        "print(\"\\n Model Information:\")\n",
        "print(f\"   Architecture: YOLOv8{model_size}\")\n",
        "print(f\"   Classes: {len(asl_classes)}\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "# Quick model summary\n",
        "try:\n",
        "    model_info = best_model.info()\n",
        "    if model_info:\n",
        "        print(f\"   Parameters: {model_info.get('params', 'Unknown'):,}\")\n",
        "        print(f\"   FLOPs: {model_info.get('flops', 'Unknown')}\")\n",
        "except:\n",
        "    print(\"   Model summary not available\")\n",
        "\n",
        "print(\"\\n Model ready for evaluation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX2TGcC_bWWj",
        "outputId": "9627c20b-732f-4644-ad67-f1e11e5b0c48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading best trained model...\n",
            " Best model loaded from: /content/asl_project/models/asl_yolov8_training/weights/best.pt\n",
            "\n",
            " Model Information:\n",
            "   Architecture: YOLOv8n\n",
            "   Classes: 36\n",
            "   Device: cuda\n",
            "Model summary: 129 layers, 3,017,868 parameters, 0 gradients, 8.2 GFLOPs\n",
            "   Model summary not available\n",
            "\n",
            " Model ready for evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive model evaluation\n",
        "print(\" Running comprehensive model evaluation...\")\n",
        "\n",
        "# Validate on test set\n",
        "try:\n",
        "    print(\"\\n Validating on test set...\")\n",
        "    validation_results = best_model.val(\n",
        "        data=str(yaml_path),\n",
        "        split='test',\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        conf=0.25,\n",
        "        iou=0.6,\n",
        "        device=device,\n",
        "        verbose=True,\n",
        "        save_json=True,\n",
        "        save_hybrid=False,\n",
        "        project=str(dirs['results']),\n",
        "        name='validation'\n",
        "    )\n",
        "\n",
        "    print(\" Validation completed!\")\n",
        "\n",
        "    # Extract key metrics\n",
        "    if hasattr(validation_results, 'box'):\n",
        "        metrics = validation_results.box\n",
        "        map50_95 = metrics.map  # mAP@0.5-0.95\n",
        "        map50 = metrics.map50   # mAP@0.5\n",
        "        precision = metrics.mp  # Mean precision\n",
        "        recall = metrics.mr     # Mean recall\n",
        "\n",
        "        print(f\"\\n Performance Metrics:\")\n",
        "        print(f\"   mAP@0.5-0.95: {map50_95:.3f} ({map50_95*100:.1f}%)\")\n",
        "        print(f\"   mAP@0.5: {map50:.3f} ({map50*100:.1f}%)\")\n",
        "        print(f\"   Precision: {precision:.3f} ({precision*100:.1f}%)\")\n",
        "        print(f\"   Recall: {recall:.3f} ({recall*100:.1f}%)\")\n",
        "\n",
        "        # Checking if we met the 90% accuracy target\n",
        "        if map50 >= 0.90:\n",
        "            print(\"\\n SUCCESS: Model achieved 90%+ accuracy target!\")\n",
        "        elif map50 >= 0.85:\n",
        "            print(\"\\n GOOD: Model achieved 85%+ accuracy (close to target)\")\n",
        "        elif map50 >= 0.75:\n",
        "            print(\"\\n  OKAY: Model achieved 75%+ accuracy (needs improvement)\")\n",
        "        else:\n",
        "            print(\"\\n  LOW: Model accuracy below 75% (requires more training/data)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Validation error: {e}\")\n",
        "    print(\"Continuing with other evaluations...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTTt9rQtbZGM",
        "outputId": "4fb085ec-65cb-43b5-eefa-c4e69e26aa20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running comprehensive model evaluation...\n",
            "\n",
            " Validating on test set...\n",
            "WARNING ⚠️ 'save_hybrid' is deprecated and will be removed in in the future.\n",
            "Ultralytics 8.3.180 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,012,668 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2876.8±1010.0 MB/s, size: 231.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/asl_project/datasets/asl_unified/test/labels... 72 images, 0 backgrounds, 0 corrupt: 100%|██████████| 72/72 [00:00<00:00, 2368.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/asl_project/datasets/asl_unified/test/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         72         72      0.942      0.889      0.942      0.915\n",
            "                     A          1          1          1          1      0.995      0.995\n",
            "                     B          3          3          1          1      0.995      0.995\n",
            "                     C          4          4      0.933          1      0.995      0.972\n",
            "                     D          1          1      0.545          1      0.995      0.995\n",
            "                     F          2          2          1          1      0.995      0.995\n",
            "                     G          5          5          1          1      0.995      0.971\n",
            "                     H          3          3          1          1      0.995      0.951\n",
            "                     I          2          2          1        0.5       0.75       0.75\n",
            "                     J          4          4       0.93          1      0.995      0.911\n",
            "                     K          4          4          1       0.75      0.875      0.875\n",
            "                     M          3          3          1      0.547      0.833        0.8\n",
            "                     N          3          3      0.617      0.667      0.639      0.506\n",
            "                     O          3          3          1      0.595      0.995      0.973\n",
            "                     P          1          1      0.845          1      0.995      0.995\n",
            "                     Q          2          2          1        0.5       0.75      0.675\n",
            "                     R          2          2          1          1      0.995      0.933\n",
            "                     S          3          3          1          1      0.995      0.995\n",
            "                     T          5          5        0.8        0.8      0.839      0.839\n",
            "                     U          2          2          1          1      0.995      0.995\n",
            "                     V          4          4          1       0.98      0.995      0.904\n",
            "                     W          5          5      0.948          1      0.995      0.995\n",
            "                     X          4          4          1          1      0.995      0.995\n",
            "                     Y          2          2          1          1      0.995      0.995\n",
            "                     Z          4          4          1          1      0.995      0.945\n",
            "Speed: 4.9ms preprocess, 9.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Saving /content/asl_project/results/validation/predictions.json...\n",
            "Results saved to \u001b[1m/content/asl_project/results/validation\u001b[0m\n",
            " Validation completed!\n",
            "\n",
            "📈 Performance Metrics:\n",
            "   mAP@0.5-0.95: 0.915 (91.5%)\n",
            "   mAP@0.5: 0.942 (94.2%)\n",
            "   Precision: 0.942 (94.2%)\n",
            "   Recall: 0.889 (88.9%)\n",
            "\n",
            " SUCCESS: Model achieved 90%+ accuracy target!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comprehensive training visualizations\n",
        "print(\" Creating training performance visualizations...\")\n",
        "\n",
        "# Look for training results\n",
        "results_dir = dirs['models'] / 'asl_yolov8_training'\n",
        "results_csv = results_dir / 'results.csv'\n",
        "\n",
        "if results_csv.exists():\n",
        "    print(\" Loading training history...\")\n",
        "\n",
        "    # Load training results\n",
        "    df = pd.read_csv(results_csv)\n",
        "\n",
        "    # Create comprehensive training dashboard\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=2,\n",
        "        subplot_titles=[\n",
        "            'Training & Validation Loss',\n",
        "            'mAP Scores Over Time',\n",
        "            'Precision & Recall',\n",
        "            'Learning Rate Schedule',\n",
        "            'Loss Components',\n",
        "            'Accuracy Progression'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    epochs = df.index + 1\n",
        "\n",
        "    # 1. Training & Validation Loss\n",
        "    if 'train/box_loss' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['train/box_loss'], name='Train Box Loss', line=dict(color='red')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "    if 'val/box_loss' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['val/box_loss'], name='Val Box Loss', line=dict(color='blue')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "    # 2. mAP Scores\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['metrics/mAP50(B)'], name='mAP@0.5', line=dict(color='green')),\n",
        "            row=1, col=2\n",
        "        )\n",
        "    if 'metrics/mAP50-95(B)' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['metrics/mAP50-95(B)'], name='mAP@0.5-0.95', line=dict(color='orange')),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "    # 3. Precision & Recall\n",
        "    if 'metrics/precision(B)' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['metrics/precision(B)'], name='Precision', line=dict(color='purple')),\n",
        "            row=2, col=1\n",
        "        )\n",
        "    if 'metrics/recall(B)' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['metrics/recall(B)'], name='Recall', line=dict(color='brown')),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "    # 4. Learning Rate\n",
        "    if 'lr/pg0' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['lr/pg0'], name='Learning Rate', line=dict(color='black')),\n",
        "            row=2, col=2\n",
        "        )\n",
        "\n",
        "    # 5. Loss Components\n",
        "    loss_cols = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']\n",
        "    colors = ['red', 'green', 'blue']\n",
        "\n",
        "    for i, (col, color) in enumerate(zip(loss_cols, colors)):\n",
        "        if col in df.columns:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=epochs, y=df[col], name=col.split('/')[-1], line=dict(color=color)),\n",
        "                row=3, col=1\n",
        "            )\n",
        "\n",
        "    # 6. Accuracy Progression (mAP50 with target line)\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=epochs, y=df['metrics/mAP50(B)'], name='Accuracy (mAP@0.5)',\n",
        "                      line=dict(color='green', width=3)),\n",
        "            row=3, col=2\n",
        "        )\n",
        "        # Add target line at 90%\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=[1, len(epochs)], y=[0.9, 0.9], name='90% Target',\n",
        "                      line=dict(color='red', dash='dash')),\n",
        "            row=3, col=2\n",
        "        )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=\"YOLOv8 ASL Training Performance Dashboard\",\n",
        "        showlegend=True,\n",
        "        height=1200,\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "\n",
        "    # Update x-axis labels\n",
        "    for i in range(1, 4):\n",
        "        for j in range(1, 3):\n",
        "            fig.update_xaxes(title_text=\"Epoch\", row=i, col=j)\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    # Print training summary\n",
        "    print(\"\\n Training Summary:\")\n",
        "    print(f\"   Total Epochs: {len(df)}\")\n",
        "\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        best_map = df['metrics/mAP50(B)'].max()\n",
        "        best_epoch = df['metrics/mAP50(B)'].idxmax() + 1\n",
        "        final_map = df['metrics/mAP50(B)'].iloc[-1]\n",
        "\n",
        "        print(f\"   Best mAP@0.5: {best_map:.3f} ({best_map*100:.1f}%) at epoch {best_epoch}\")\n",
        "        print(f\"   Final mAP@0.5: {final_map:.3f} ({final_map*100:.1f}%)\")\n",
        "\n",
        "        if best_map >= 0.90:\n",
        "            print(\"    TARGET ACHIEVED: Model reached 90%+ accuracy!\")\n",
        "        else:\n",
        "            improvement_needed = (0.90 - best_map) * 100\n",
        "            print(f\"    Need {improvement_needed:.1f}% more accuracy to reach 90% target\")\n",
        "\n",
        "    # Save visualization\n",
        "    viz_path = dirs['visualizations'] / 'training_dashboard.html'\n",
        "    fig.write_html(str(viz_path))\n",
        "    print(f\"\\n Training dashboard saved: {viz_path}\")\n",
        "\n",
        "else:\n",
        "    print(\" Training results not found. Skipping training visualizations.\")\n",
        "    print(\"   This might happen if training was interrupted or failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "27tQWE6XbdJv",
        "outputId": "8f6ac542-9983-4d05-ca48-8ceaa333ffe4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating training performance visualizations...\n",
            " Loading training history...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ae7d00d8-f9ea-4b0c-996e-d2d6742c1016\" class=\"plotly-graph-div\" style=\"height:1200px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ae7d00d8-f9ea-4b0c-996e-d2d6742c1016\")) {                    Plotly.newPlot(                        \"ae7d00d8-f9ea-4b0c-996e-d2d6742c1016\",                        [{\"line\":{\"color\":\"red\"},\"name\":\"Train Box Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.00617,0.00508,0.00507,0.00496,0.00517,0.00495,0.00495,0.00482,0.00453,0.00444,0.00466,0.00438,0.00422,0.00435,0.00429,0.00408,0.00423,0.00403,0.00391,0.00368,0.00394,0.00383,0.00365,0.00399,0.00379,0.00394,0.00388,0.00384,0.00378,0.00382,0.00375,0.00341,0.00365,0.0037,0.00346,0.00348,0.00353,0.00358,0.00356,0.00342,0.00332,0.00355,0.00348,0.00344,0.00347,0.00333,0.0033,0.00344,0.00347,0.00329,0.00348,0.00317,0.00331,0.00338,0.00327,0.00331,0.00329,0.00324,0.00312,0.00327,0.00316,0.00307,0.00315,0.00321,0.00317,0.00309,0.00314,0.00304,0.00305,0.00313,0.0031,0.0031,0.00316,0.00299,0.00301,0.00307,0.00293,0.00307,0.00294,0.00302,0.00301,0.00291,0.00291,0.00299,0.00288,0.0029,0.0029,0.00288,0.00282,0.00305,0.00188,0.00188,0.0018,0.00183,0.00185,0.00172,0.00176,0.00172,0.00173,0.00175],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"blue\"},\"name\":\"Val Box Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.00319,0.00326,0.00359,0.00399,0.0036,0.00347,0.00358,0.00345,0.00343,0.00354,0.0034,0.00341,0.00322,0.00339,0.00313,0.00313,0.00319,0.00312,0.00301,0.00313,0.00292,0.003,0.00285,0.00284,0.00281,0.00298,0.00302,0.00296,0.00286,0.00273,0.00277,0.00288,0.00278,0.0027,0.00282,0.00272,0.00267,0.00282,0.00284,0.00282,0.00281,0.00272,0.0027,0.0027,0.00268,0.00284,0.00264,0.00289,0.00267,0.00258,0.00268,0.00264,0.00266,0.00268,0.0027,0.00264,0.0027,0.00254,0.00262,0.00264,0.00252,0.00263,0.00266,0.00262,0.00257,0.00251,0.00249,0.00259,0.00261,0.00256,0.00253,0.00246,0.0025,0.00249,0.00256,0.00246,0.00242,0.00252,0.0025,0.00254,0.00247,0.00249,0.00253,0.00253,0.00254,0.00244,0.00242,0.00241,0.00243,0.00241,0.00246,0.00245,0.00239,0.00258,0.00254,0.0025,0.00246,0.00241,0.00241,0.00242],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"green\"},\"name\":\"mAP@0.5\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0,0.09861,0.21941,0.38459,0.53262,0.58122,0.68649,0.72961,0.78412,0.8016,0.80072,0.84228,0.8303,0.87673,0.86343,0.85966,0.88688,0.87451,0.89749,0.8964,0.91767,0.89872,0.90843,0.90564,0.93,0.91388,0.91954,0.93825,0.92908,0.93156,0.92526,0.93111,0.93058,0.93134,0.93513,0.94228,0.95215,0.94357,0.94172,0.93704,0.95203,0.95209,0.95011,0.93011,0.94085,0.92944,0.93163,0.92982,0.93797,0.94208,0.93887,0.94568,0.95998,0.95893,0.95581,0.95848,0.9555,0.95596,0.96012,0.95474,0.96554,0.95788,0.95971,0.96209,0.95629,0.9585,0.96719,0.96797,0.96102,0.95966,0.96181,0.95447,0.95677,0.95999,0.96351,0.9643,0.96354,0.96482,0.95966,0.96825,0.96434,0.95864,0.95855,0.9546,0.95416,0.95757,0.94528,0.95114,0.96145,0.95638,0.95376,0.95415,0.95536,0.95295,0.96122,0.9628,0.96681,0.96666,0.96517,0.96405],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"orange\"},\"name\":\"mAP@0.5-0.95\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0,0.0887,0.19737,0.3307,0.46796,0.51597,0.61461,0.65125,0.6968,0.70297,0.71202,0.75534,0.75412,0.79782,0.7916,0.79102,0.81363,0.8003,0.82598,0.8247,0.84689,0.82684,0.83213,0.8353,0.85979,0.84331,0.84961,0.87068,0.86094,0.86273,0.85625,0.86105,0.86533,0.86526,0.86885,0.88435,0.89442,0.87331,0.87542,0.87035,0.88411,0.89293,0.89026,0.86367,0.88129,0.85958,0.87255,0.86582,0.87569,0.88321,0.87669,0.88425,0.90005,0.89462,0.9004,0.90137,0.8893,0.89713,0.89626,0.89341,0.90506,0.89684,0.89693,0.90683,0.90284,0.90349,0.90927,0.91171,0.90252,0.90456,0.90338,0.90011,0.90526,0.90508,0.90732,0.90894,0.91253,0.91341,0.90135,0.90526,0.9024,0.90496,0.90021,0.89901,0.89778,0.90233,0.88999,0.89673,0.90606,0.90464,0.89763,0.90278,0.90315,0.89089,0.9039,0.90837,0.91184,0.91256,0.91276,0.91673],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"purple\"},\"name\":\"Precision\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0,0.02983,0.45309,0.41937,0.32782,0.48097,0.53978,0.64178,0.6741,0.74342,0.66909,0.7947,0.64608,0.75502,0.79877,0.77009,0.73417,0.7704,0.74905,0.80136,0.86286,0.80272,0.80417,0.89371,0.84346,0.8023,0.85495,0.87047,0.84846,0.83842,0.90964,0.81216,0.89306,0.87575,0.8336,0.88694,0.91196,0.88566,0.89476,0.83896,0.94465,0.90743,0.90564,0.83712,0.90195,0.91065,0.87727,0.88982,0.89363,0.87274,0.89163,0.89377,0.88418,0.94305,0.94412,0.93994,0.94234,0.89779,0.91696,0.91068,0.90779,0.93348,0.90135,0.93404,0.89938,0.90759,0.88443,0.91435,0.92956,0.92799,0.91532,0.92757,0.9408,0.95723,0.94269,0.93546,0.94129,0.90855,0.90993,0.94408,0.93594,0.93846,0.91726,0.92763,0.91424,0.92351,0.91784,0.93511,0.92634,0.94489,0.89347,0.90072,0.92384,0.92013,0.90874,0.92352,0.9123,0.90752,0.9257,0.92743],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"brown\"},\"name\":\"Recall\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0,0.6679,0.27546,0.36379,0.57229,0.59692,0.61429,0.63063,0.6585,0.70988,0.70786,0.69143,0.78834,0.77815,0.79334,0.77061,0.82709,0.78948,0.85372,0.8499,0.86711,0.84197,0.82347,0.82431,0.8533,0.8503,0.85232,0.85551,0.84155,0.83631,0.842,0.88328,0.84062,0.8417,0.87721,0.86035,0.84533,0.85518,0.85089,0.89191,0.86995,0.83773,0.87497,0.87856,0.86342,0.83897,0.89189,0.83229,0.88676,0.87726,0.86776,0.88027,0.91078,0.88077,0.85554,0.8917,0.85997,0.90066,0.87829,0.90186,0.89052,0.85065,0.90203,0.86062,0.89268,0.89051,0.93431,0.91544,0.91622,0.89369,0.89517,0.8764,0.89344,0.89832,0.90243,0.89897,0.88261,0.90816,0.90784,0.87784,0.88602,0.88163,0.89238,0.88315,0.89204,0.91521,0.90836,0.8967,0.9017,0.88124,0.89289,0.90281,0.90122,0.90316,0.91316,0.90588,0.91228,0.91368,0.89858,0.89427],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"black\"},\"name\":\"Learning Rate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0000775,0.000156082,0.000233225,0.00024325,0.000241,0.00023875,0.0002365,0.00023425,0.000232,0.00022975,0.0002275,0.00022525,0.000223,0.00022075,0.0002185,0.00021625,0.000214,0.00021175,0.0002095,0.00020725,0.000205,0.00020275,0.0002005,0.00019825,0.000196,0.00019375,0.0001915,0.00018925,0.000187,0.00018475,0.0001825,0.00018025,0.000178,0.00017575,0.0001735,0.00017125,0.000169,0.00016675,0.0001645,0.00016225,0.00016,0.00015775,0.0001555,0.00015325,0.000151,0.00014875,0.0001465,0.00014425,0.000142,0.00013975,0.0001375,0.00013525,0.000133,0.00013075,0.0001285,0.00012625,0.000124,0.00012175,0.0001195,0.00011725,0.000115,0.00011275,0.0001105,0.00010825,0.000106,0.00010375,0.0001015,0.00009925,0.000097,0.00009475,0.0000925,0.00009025,0.000088,0.00008575,0.0000835,0.00008125,0.000079,0.00007675,0.0000745,0.00007225,0.00007,0.00006775,0.0000655,0.00006325,0.000061,0.00005875,0.0000565,0.00005425,0.000052,0.00004975,0.0000475,0.00004525,0.000043,0.00004075,0.0000385,0.00003625,0.000034,0.00003175,0.0000295,0.00002725],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"line\":{\"color\":\"red\"},\"name\":\"box_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.00617,0.00508,0.00507,0.00496,0.00517,0.00495,0.00495,0.00482,0.00453,0.00444,0.00466,0.00438,0.00422,0.00435,0.00429,0.00408,0.00423,0.00403,0.00391,0.00368,0.00394,0.00383,0.00365,0.00399,0.00379,0.00394,0.00388,0.00384,0.00378,0.00382,0.00375,0.00341,0.00365,0.0037,0.00346,0.00348,0.00353,0.00358,0.00356,0.00342,0.00332,0.00355,0.00348,0.00344,0.00347,0.00333,0.0033,0.00344,0.00347,0.00329,0.00348,0.00317,0.00331,0.00338,0.00327,0.00331,0.00329,0.00324,0.00312,0.00327,0.00316,0.00307,0.00315,0.00321,0.00317,0.00309,0.00314,0.00304,0.00305,0.00313,0.0031,0.0031,0.00316,0.00299,0.00301,0.00307,0.00293,0.00307,0.00294,0.00302,0.00301,0.00291,0.00291,0.00299,0.00288,0.0029,0.0029,0.00288,0.00282,0.00305,0.00188,0.00188,0.0018,0.00183,0.00185,0.00172,0.00176,0.00172,0.00173,0.00175],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"line\":{\"color\":\"green\"},\"name\":\"cls_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[4.51253,4.08596,3.68299,3.31311,3.0929,2.87419,2.62215,2.51233,2.28118,2.20627,2.06138,1.95878,1.88675,1.83287,1.75806,1.65416,1.64768,1.52219,1.59067,1.43578,1.44565,1.44903,1.30381,1.38196,1.37508,1.32444,1.30894,1.26004,1.25259,1.23357,1.23036,1.14815,1.16369,1.18446,1.09747,1.10314,1.09377,1.09458,1.10154,1.06373,1.03385,1.02618,0.98316,1.01615,0.98256,1.00331,0.96183,0.94673,0.95096,0.94245,0.94631,0.91501,0.9256,0.9617,0.91072,0.91829,0.86432,0.86628,0.85327,0.90014,0.84778,0.82146,0.84099,0.86269,0.82298,0.81826,0.84788,0.79177,0.77219,0.79478,0.8017,0.79856,0.80447,0.76381,0.77166,0.75965,0.72112,0.74263,0.73299,0.74425,0.72993,0.73293,0.69897,0.72551,0.68261,0.70343,0.69667,0.68974,0.66767,0.72504,0.72389,0.70267,0.66208,0.65047,0.65558,0.63705,0.62693,0.61783,0.61866,0.60566],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"line\":{\"color\":\"blue\"},\"name\":\"dfl_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[1.32218,1.20285,1.19653,1.20289,1.21333,1.18388,1.18865,1.17579,1.14508,1.12822,1.14515,1.11603,1.10619,1.088,1.09642,1.07518,1.07202,1.05217,1.06386,1.02722,1.04414,1.05672,1.01744,1.0625,1.03949,1.04703,1.04589,1.03483,1.03547,1.03188,1.03714,0.99751,1.02715,1.03216,0.99879,1.00668,1.00242,1.02112,1.00366,0.99979,0.99077,1.00407,0.99465,1.00836,1.00247,0.99583,0.97869,1.00901,1.00789,0.98577,1.00827,0.98407,0.98506,1.01943,0.98441,0.98827,0.985,0.9845,0.98322,0.98698,0.97856,0.96745,0.98341,0.99979,0.96706,0.97763,0.98195,0.96326,0.97461,0.98272,0.96746,0.97146,0.97821,0.96213,0.97158,0.97151,0.95295,0.96754,0.96307,0.98065,0.96736,0.96371,0.95048,0.95497,0.95572,0.95338,0.96975,0.95867,0.96119,0.96114,0.85022,0.84711,0.84355,0.83899,0.85937,0.8398,0.84508,0.83683,0.84031,0.84519],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"line\":{\"color\":\"green\",\"width\":3},\"name\":\"Accuracy (mAP@0.5)\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.0,0.09861,0.21941,0.38459,0.53262,0.58122,0.68649,0.72961,0.78412,0.8016,0.80072,0.84228,0.8303,0.87673,0.86343,0.85966,0.88688,0.87451,0.89749,0.8964,0.91767,0.89872,0.90843,0.90564,0.93,0.91388,0.91954,0.93825,0.92908,0.93156,0.92526,0.93111,0.93058,0.93134,0.93513,0.94228,0.95215,0.94357,0.94172,0.93704,0.95203,0.95209,0.95011,0.93011,0.94085,0.92944,0.93163,0.92982,0.93797,0.94208,0.93887,0.94568,0.95998,0.95893,0.95581,0.95848,0.9555,0.95596,0.96012,0.95474,0.96554,0.95788,0.95971,0.96209,0.95629,0.9585,0.96719,0.96797,0.96102,0.95966,0.96181,0.95447,0.95677,0.95999,0.96351,0.9643,0.96354,0.96482,0.95966,0.96825,0.96434,0.95864,0.95855,0.9546,0.95416,0.95757,0.94528,0.95114,0.96145,0.95638,0.95376,0.95415,0.95536,0.95295,0.96122,0.9628,0.96681,0.96666,0.96517,0.96405],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"line\":{\"color\":\"red\",\"dash\":\"dash\"},\"name\":\"90% Target\",\"x\":[1,100],\"y\":[0.9,0.9],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.7777777777777778,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.7777777777777778,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.3888888888888889,0.6111111111111112]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.3888888888888889,0.6111111111111112]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.22222222222222224]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.22222222222222224]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training & Validation Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"mAP Scores Over Time\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Precision & Recall\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6111111111111112,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Learning Rate Schedule\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6111111111111112,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss Components\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.22222222222222224,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy Progression\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.22222222222222224,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"YOLOv8 ASL Training Performance Dashboard\"},\"showlegend\":true,\"height\":1200,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ae7d00d8-f9ea-4b0c-996e-d2d6742c1016');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training Summary:\n",
            "   Total Epochs: 100\n",
            "   Best mAP@0.5: 0.968 (96.8%) at epoch 80\n",
            "   Final mAP@0.5: 0.964 (96.4%)\n",
            "    TARGET ACHIEVED: Model reached 90%+ accuracy!\n",
            "\n",
            " Training dashboard saved: /content/asl_project/visualizations/training_dashboard.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix and per-class analysis\n",
        "print(\" Creating detailed performance analysis...\")\n",
        "\n",
        "# Test on validation set to get predictions\n",
        "val_images_dir = unified_dir / 'val' / 'images'\n",
        "\n",
        "if val_images_dir.exists():\n",
        "    print(\"\\n Running predictions on validation set...\")\n",
        "\n",
        "    # Get validation images\n",
        "    val_images = list(val_images_dir.glob('*'))\n",
        "\n",
        "    if val_images:\n",
        "        # Sample subset for detailed analysis (to avoid memory issues)\n",
        "        sample_size = min(500, len(val_images))\n",
        "        sample_images = val_images[:sample_size]\n",
        "\n",
        "        print(f\"   Analyzing {len(sample_images)} validation images...\")\n",
        "\n",
        "        # Run predictions\n",
        "        predictions = best_model.predict(\n",
        "            source=[str(img) for img in sample_images],\n",
        "            conf=0.25,\n",
        "            iou=0.6,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Collect predictions and ground truth\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        class_accuracies = defaultdict(list)\n",
        "\n",
        "        for i, (img_path, pred) in enumerate(zip(sample_images, predictions)):\n",
        "            # Get ground truth from label file\n",
        "            label_path = unified_dir / 'val' / 'labels' / f\"{img_path.stem}.txt\"\n",
        "\n",
        "            if label_path.exists():\n",
        "                with open(label_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                # Get ground truth classes\n",
        "                gt_classes = [int(line.strip().split()[0]) for line in lines if line.strip()]\n",
        "\n",
        "                # Get predicted classes\n",
        "                if pred.boxes is not None and len(pred.boxes) > 0:\n",
        "                    pred_classes = pred.boxes.cls.cpu().numpy().astype(int)\n",
        "                    confidences = pred.boxes.conf.cpu().numpy()\n",
        "\n",
        "                    # For each ground truth, find best matching prediction\n",
        "                    for gt_class in gt_classes:\n",
        "                        y_true.append(gt_class)\n",
        "\n",
        "                        # Find if this class was predicted\n",
        "                        if gt_class in pred_classes:\n",
        "                            # Get confidence for this class\n",
        "                            class_mask = pred_classes == gt_class\n",
        "                            max_conf = confidences[class_mask].max() if np.any(class_mask) else 0\n",
        "                            y_pred.append(gt_class)\n",
        "                            class_accuracies[gt_class].append(1)\n",
        "                        else:\n",
        "                            # Class not detected correctly\n",
        "                            if len(pred_classes) > 0:\n",
        "                                # Use highest confidence prediction\n",
        "                                best_pred_idx = np.argmax(confidences)\n",
        "                                y_pred.append(pred_classes[best_pred_idx])\n",
        "                            else:\n",
        "                                # No prediction\n",
        "                                y_pred.append(-1)  # Use -1 for no detection\n",
        "                            class_accuracies[gt_class].append(0)\n",
        "                else:\n",
        "                    # No detections for this image\n",
        "                    for gt_class in gt_classes:\n",
        "                        y_true.append(gt_class)\n",
        "                        y_pred.append(-1)\n",
        "                        class_accuracies[gt_class].append(0)\n",
        "\n",
        "        if y_true and y_pred:\n",
        "            print(f\"   Processed {len(y_true)} annotations\")\n",
        "\n",
        "            # Create confusion matrix\n",
        "            print(\"\\n Generating confusion matrix...\")\n",
        "\n",
        "            # Get unique classes that appear in predictions\n",
        "            unique_classes = sorted(list(set(y_true + y_pred)))\n",
        "            class_names = []\n",
        "\n",
        "            for cls_id in unique_classes:\n",
        "                if cls_id == -1:\n",
        "                    class_names.append('No Detection')\n",
        "                elif 0 <= cls_id < len(yaml_config['names']):\n",
        "                    class_names.append(yaml_config['names'][cls_id])\n",
        "                else:\n",
        "                    class_names.append(f'Class_{cls_id}')\n",
        "\n",
        "            # Compute confusion matrix\n",
        "            cm = confusion_matrix(y_true, y_pred, labels=unique_classes)\n",
        "\n",
        "            # Create interactive confusion matrix\n",
        "            fig_cm = go.Figure(data=go.Heatmap(\n",
        "                z=cm,\n",
        "                x=class_names,\n",
        "                y=class_names,\n",
        "                colorscale='Blues',\n",
        "                showscale=True,\n",
        "                text=cm,\n",
        "                texttemplate=\"%{text}\",\n",
        "                textfont={\"size\": 10},\n",
        "                hoverongaps=False\n",
        "            ))\n",
        "\n",
        "            fig_cm.update_layout(\n",
        "                title='ASL Detection Confusion Matrix',\n",
        "                xaxis_title='Predicted Class',\n",
        "                yaxis_title='True Class',\n",
        "                width=800,\n",
        "                height=800\n",
        "            )\n",
        "\n",
        "            fig_cm.show()\n",
        "\n",
        "            # Per-class accuracy analysis\n",
        "            print(\"\\n Per-class accuracy analysis:\")\n",
        "\n",
        "            class_stats = []\n",
        "\n",
        "            for class_id in sorted(class_accuracies.keys()):\n",
        "                if 0 <= class_id < len(yaml_config['names']):\n",
        "                    class_name = yaml_config['names'][class_id]\n",
        "                    accuracies = class_accuracies[class_id]\n",
        "\n",
        "                    if accuracies:\n",
        "                        class_acc = np.mean(accuracies)\n",
        "                        sample_count = len(accuracies)\n",
        "\n",
        "                        class_stats.append({\n",
        "                            'Class': class_name,\n",
        "                            'ID': class_id,\n",
        "                            'Accuracy': class_acc,\n",
        "                            'Samples': sample_count\n",
        "                        })\n",
        "\n",
        "            if class_stats:\n",
        "                # Create DataFrame and sort by accuracy\n",
        "                df_stats = pd.DataFrame(class_stats).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "                # Display top and bottom performing classes\n",
        "                print(\"\\n Top 10 performing classes:\")\n",
        "                for _, row in df_stats.head(10).iterrows():\n",
        "                    print(f\"   {row['Class']}: {row['Accuracy']:.2%} ({row['Samples']} samples)\")\n",
        "\n",
        "                print(\"\\n Bottom 10 performing classes:\")\n",
        "                for _, row in df_stats.tail(10).iterrows():\n",
        "                    print(f\"   {row['Class']}: {row['Accuracy']:.2%} ({row['Samples']} samples)\")\n",
        "\n",
        "                # Create per-class accuracy chart\n",
        "                fig_acc = px.bar(\n",
        "                    df_stats,\n",
        "                    x='Class',\n",
        "                    y='Accuracy',\n",
        "                    title='Per-Class Detection Accuracy',\n",
        "                    color='Accuracy',\n",
        "                    color_continuous_scale='RdYlGn',\n",
        "                    hover_data=['Samples']\n",
        "                )\n",
        "\n",
        "                fig_acc.update_layout(\n",
        "                    xaxis_tickangle=-45,\n",
        "                    height=600,\n",
        "                    yaxis_title=\"Accuracy (%)\"\n",
        "                )\n",
        "\n",
        "                fig_acc.show()\n",
        "\n",
        "                # Save detailed results\n",
        "                results_path = dirs['results'] / 'class_performance.csv'\n",
        "                df_stats.to_csv(results_path, index=False)\n",
        "                print(f\"\\n Detailed results saved: {results_path}\")\n",
        "\n",
        "                # Overall statistics\n",
        "                overall_acc = df_stats['Accuracy'].mean()\n",
        "                print(f\"\\n Overall Statistics:\")\n",
        "                print(f\"   Average class accuracy: {overall_acc:.2%}\")\n",
        "                print(f\"   Best class: {df_stats.iloc[0]['Class']} ({df_stats.iloc[0]['Accuracy']:.2%})\")\n",
        "                print(f\"   Worst class: {df_stats.iloc[-1]['Class']} ({df_stats.iloc[-1]['Accuracy']:.2%})\")\n",
        "                print(f\"   Classes above 90%: {len(df_stats[df_stats['Accuracy'] >= 0.9])}\")\n",
        "                print(f\"   Classes below 50%: {len(df_stats[df_stats['Accuracy'] < 0.5])}\")\n",
        "\n",
        "        else:\n",
        "            print(\" No valid predictions found for analysis\")\n",
        "\n",
        "    else:\n",
        "        print(\" No validation images found\")\n",
        "\n",
        "else:\n",
        "    print(\" Validation directory not found. Skipping detailed analysis.\")\n",
        "\n",
        "print(\"\\n Performance analysis completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wUHTEMUJbfza",
        "outputId": "adc48012-9225-47c7-f18a-6ef3c9ec7db1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating detailed performance analysis...\n",
            "\n",
            " Running predictions on validation set...\n",
            "   Analyzing 144 validation images...\n",
            "   Processed 144 annotations\n",
            "\n",
            " Generating confusion matrix...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"47e45f49-c703-4d73-a197-79bd32540088\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"47e45f49-c703-4d73-a197-79bd32540088\")) {                    Plotly.newPlot(                        \"47e45f49-c703-4d73-a197-79bd32540088\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"hoverongaps\":false,\"showscale\":true,\"text\":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],[0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,6,2,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,7,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4]],\"textfont\":{\"size\":10},\"texttemplate\":\"%{text}\",\"x\":[\"No Detection\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"],\"y\":[\"No Detection\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"],\"z\":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],[0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,6,2,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,7,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"ASL Detection Confusion Matrix\"},\"xaxis\":{\"title\":{\"text\":\"Predicted Class\"}},\"yaxis\":{\"title\":{\"text\":\"True Class\"}},\"width\":800,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('47e45f49-c703-4d73-a197-79bd32540088');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Per-class accuracy analysis:\n",
            "\n",
            " Top 10 performing classes:\n",
            "   B: 100.00% (9 samples)\n",
            "   C: 100.00% (3 samples)\n",
            "   G: 100.00% (5 samples)\n",
            "   D: 100.00% (6 samples)\n",
            "   E: 100.00% (4 samples)\n",
            "   F: 100.00% (8 samples)\n",
            "   J: 100.00% (8 samples)\n",
            "   H: 100.00% (9 samples)\n",
            "   L: 100.00% (4 samples)\n",
            "   K: 100.00% (6 samples)\n",
            "\n",
            " Bottom 10 performing classes:\n",
            "   U: 100.00% (7 samples)\n",
            "   S: 100.00% (4 samples)\n",
            "   Y: 87.50% (8 samples)\n",
            "   P: 85.71% (7 samples)\n",
            "   O: 85.71% (7 samples)\n",
            "   A: 80.00% (5 samples)\n",
            "   V: 80.00% (5 samples)\n",
            "   M: 75.00% (8 samples)\n",
            "   T: 66.67% (6 samples)\n",
            "   I: 50.00% (2 samples)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"96b77a1c-c1d9-44b0-be1a-cc47f92ff676\" class=\"plotly-graph-div\" style=\"height:600px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96b77a1c-c1d9-44b0-be1a-cc47f92ff676\")) {                    Plotly.newPlot(                        \"96b77a1c-c1d9-44b0-be1a-cc47f92ff676\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[9],[3],[5],[6],[4],[8],[8],[9],[4],[6],[4],[3],[4],[7],[4],[1],[7],[4],[8],[7],[7],[5],[5],[8],[6],[2]],\"hovertemplate\":\"Class=%{x}\\u003cbr\\u003eAccuracy=%{marker.color}\\u003cbr\\u003eSamples=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.875,0.8571428571428571,0.8571428571428571,0.8,0.8,0.75,0.6666666666666666,0.5],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"B\",\"C\",\"G\",\"D\",\"E\",\"F\",\"J\",\"H\",\"L\",\"K\",\"Z\",\"W\",\"N\",\"R\",\"Q\",\"X\",\"U\",\"S\",\"Y\",\"P\",\"O\",\"A\",\"V\",\"M\",\"T\",\"I\"],\"xaxis\":\"x\",\"y\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.875,0.8571428571428571,0.8571428571428571,0.8,0.8,0.75,0.6666666666666666,0.5],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class\"},\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy (%)\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Accuracy\"}},\"colorscale\":[[0.0,\"rgb(165,0,38)\"],[0.1,\"rgb(215,48,39)\"],[0.2,\"rgb(244,109,67)\"],[0.3,\"rgb(253,174,97)\"],[0.4,\"rgb(254,224,139)\"],[0.5,\"rgb(255,255,191)\"],[0.6,\"rgb(217,239,139)\"],[0.7,\"rgb(166,217,106)\"],[0.8,\"rgb(102,189,99)\"],[0.9,\"rgb(26,152,80)\"],[1.0,\"rgb(0,104,55)\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Per-Class Detection Accuracy\"},\"barmode\":\"relative\",\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('96b77a1c-c1d9-44b0-be1a-cc47f92ff676');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Detailed results saved: /content/asl_project/results/class_performance.csv\n",
            "\n",
            " Overall Statistics:\n",
            "   Average class accuracy: 92.72%\n",
            "   Best class: B (100.00%)\n",
            "   Worst class: I (50.00%)\n",
            "   Classes above 90%: 18\n",
            "   Classes below 50%: 0\n",
            "\n",
            " Performance analysis completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create interactive image upload interface\n",
        "print(\" Image Upload & Prediction Interface\")\n",
        "print(\"Upload ASL images to test the trained model!\\n\")\n",
        "\n",
        "# Function to process uploaded images\n",
        "def process_uploaded_image(image_path, show_results=True):\n",
        "    \"\"\"Process uploaded image and return predictions with visualization\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Run prediction\n",
        "        results = best_model.predict(\n",
        "            source=image_path,\n",
        "            conf=0.25,  # Confidence threshold\n",
        "            iou=0.6,    # IoU threshold\n",
        "            verbose=False,\n",
        "            save=False\n",
        "        )\n",
        "\n",
        "        # Load original image\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = []\n",
        "\n",
        "        if results and len(results) > 0:\n",
        "            result = results[0]\n",
        "\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                boxes = result.boxes.xyxy.cpu().numpy()\n",
        "                confidences = result.boxes.conf.cpu().numpy()\n",
        "                class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "                # Process each detection\n",
        "                for i in range(len(boxes)):\n",
        "                    class_id = class_ids[i]\n",
        "                    confidence = confidences[i]\n",
        "\n",
        "                    if 0 <= class_id < len(yaml_config['names']):\n",
        "                        class_name = yaml_config['names'][class_id]\n",
        "\n",
        "                        predictions.append({\n",
        "                            'class': class_name,\n",
        "                            'confidence': confidence,\n",
        "                            'box': boxes[i]\n",
        "                        })\n",
        "\n",
        "        if show_results:\n",
        "            # Create visualization\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "            # Original image\n",
        "            axes[0].imshow(image_rgb)\n",
        "            axes[0].set_title('Original Image')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # Annotated image\n",
        "            annotated_image = image_rgb.copy()\n",
        "\n",
        "            for pred in predictions:\n",
        "                box = pred['box']\n",
        "                x1, y1, x2, y2 = box.astype(int)\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                # Add label\n",
        "                label = f\"{pred['class']}: {pred['confidence']:.2f}\"\n",
        "                cv2.putText(annotated_image, label, (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            axes[1].imshow(annotated_image)\n",
        "            axes[1].set_title('Predictions')\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Print predictions\n",
        "            if predictions:\n",
        "                print(\"\\n Detected ASL Signs:\")\n",
        "                for i, pred in enumerate(predictions, 1):\n",
        "                    print(f\"   {i}. {pred['class']} (confidence: {pred['confidence']:.2%})\")\n",
        "\n",
        "                # Implement capitalization logic\n",
        "                detected_letters = [pred['class'] for pred in predictions if pred['class'].isalpha()]\n",
        "                if detected_letters:\n",
        "                    print(\"\\n Capitalization Options:\")\n",
        "                    letters_text = ''.join(detected_letters)\n",
        "                    print(f\"   Lowercase: {letters_text.lower()}\")\n",
        "                    print(f\"   Uppercase: {letters_text.upper()}\")\n",
        "                    print(f\"   Title Case: {letters_text.title()}\")\n",
        "            else:\n",
        "                print(\"\\n No ASL signs detected. Try:\")\n",
        "                print(\"   - Better lighting\")\n",
        "                print(\"   - Clearer hand position\")\n",
        "                print(\"   - Different camera angle\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing image: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to handle file upload\n",
        "def upload_and_predict():\n",
        "    \"\"\"Handle file upload and prediction\"\"\"\n",
        "    print(\" Please upload an ASL image (JPG, PNG formats supported)\")\n",
        "\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"\\n Processing: {filename}\")\n",
        "\n",
        "            # Save uploaded file\n",
        "            upload_path = dirs['predictions'] / filename\n",
        "            with open(upload_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "\n",
        "            # Process the image\n",
        "            predictions = process_uploaded_image(upload_path)\n",
        "\n",
        "            if predictions:\n",
        "                print(f\"\\n Successfully processed {filename}\")\n",
        "            else:\n",
        "                print(f\"\\n No detections in {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Upload error: {e}\")\n",
        "\n",
        "print(\" Image upload interface ready!\")\n",
        "print(\"Run upload_and_predict() to start uploading images\")\n",
        "print(\"\\nTips for best results:\")\n",
        "print(\"    Use clear, well-lit images\")\n",
        "print(\"    Ensure hand is clearly visible\")\n",
        "print(\"    Center the ASL sign in the image\")\n",
        "print(\"    Use images similar to training data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMNSmrwbk0U",
        "outputId": "45dc4da9-3a3e-42d4-c10f-f832b55fe5ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Image Upload & Prediction Interface\n",
            "Upload ASL images to test the trained model!\n",
            "\n",
            " Image upload interface ready!\n",
            "Run upload_and_predict() to start uploading images\n",
            "\n",
            "Tips for best results:\n",
            "    Use clear, well-lit images\n",
            "    Ensure hand is clearly visible\n",
            "    Center the ASL sign in the image\n",
            "    Use images similar to training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive upload button\n",
        "upload_button = widgets.Button(\n",
        "    description=' Upload ASL Image',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Click to upload an ASL image for prediction',\n",
        "    icon='upload'\n",
        ")\n",
        "\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "def on_upload_click(b):\n",
        "    with output_widget:\n",
        "        clear_output(wait=True)\n",
        "        upload_and_predict()\n",
        "\n",
        "upload_button.on_click(on_upload_click)\n",
        "\n",
        "# Display interface\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3> ASL Image Prediction Interface</h3>\"),\n",
        "    widgets.HTML(\"<p>Upload your ASL images to test the trained model!</p>\"),\n",
        "    upload_button,\n",
        "    output_widget\n",
        "]))\n",
        "\n",
        "print(\"\\n Use the upload button above to test your ASL images!\")"
      ],
      "metadata": {
        "id": "XG6qbxgq1-2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time webcam detection (Note: Limited in Colab environment)\n",
        "print(\" Real-Time ASL Detection Setup\")\n",
        "print(\"\\n Note: Webcam access is limited in Google Colab.\")\n",
        "print(\"For full real-time detection, download this notebook and run locally.\\n\")\n",
        "\n",
        "# Function for webcam detection (works locally)\n",
        "def real_time_asl_detection(duration=30):\n",
        "    \"\"\"\n",
        "    Real-time ASL detection using webcam\n",
        "    This function works when running locally, not in Colab\n",
        "    \"\"\"\n",
        "    print(f\" Starting real-time ASL detection for {duration} seconds...\")\n",
        "    print(\"Press 'q' to quit early\\n\")\n",
        "\n",
        "    try:\n",
        "        import cv2\n",
        "        from collections import deque, Counter\n",
        "        import time\n",
        "\n",
        "        # Initialize camera\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        if not cap.isOpened():\n",
        "            print(\" Cannot access webcam. Make sure it's connected and not in use.\")\n",
        "            return\n",
        "\n",
        "        # Detection history for stability\n",
        "        detection_history = deque(maxlen=10)\n",
        "        stable_detections = []\n",
        "\n",
        "        start_time = time.time()\n",
        "        frame_count = 0\n",
        "\n",
        "        print(\" Webcam initialized. Starting detection...\")\n",
        "\n",
        "        while time.time() - start_time < duration:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\" Failed to read from webcam\")\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Run detection every 3 frames for performance\n",
        "            if frame_count % 3 == 0:\n",
        "                # Run YOLOv8 prediction\n",
        "                results = best_model.predict(\n",
        "                    source=frame,\n",
        "                    conf=0.3,\n",
        "                    verbose=False,\n",
        "                    save=False\n",
        "                )\n",
        "\n",
        "                current_detections = []\n",
        "\n",
        "                if results and len(results) > 0:\n",
        "                    result = results[0]\n",
        "\n",
        "                    if result.boxes is not None and len(result.boxes) > 0:\n",
        "                        boxes = result.boxes.xyxy.cpu().numpy()\n",
        "                        confidences = result.boxes.conf.cpu().numpy()\n",
        "                        class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "                        # Draw detections on frame\n",
        "                        for i in range(len(boxes)):\n",
        "                            if confidences[i] > 0.3:  # Confidence threshold\n",
        "                                class_id = class_ids[i]\n",
        "\n",
        "                                if 0 <= class_id < len(yaml_config['names']):\n",
        "                                    class_name = yaml_config['names'][class_id]\n",
        "                                    confidence = confidences[i]\n",
        "\n",
        "                                    # Bounding box coordinates\n",
        "                                    x1, y1, x2, y2 = boxes[i].astype(int)\n",
        "\n",
        "                                    # Draw bounding box\n",
        "                                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                                    # Add label\n",
        "                                    label = f\"{class_name}: {confidence:.2f}\"\n",
        "                                    cv2.putText(frame, label, (x1, y1-10),\n",
        "                                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "                                    current_detections.append(class_name)\n",
        "\n",
        "                # Update detection history\n",
        "                detection_history.append(current_detections)\n",
        "\n",
        "                # Check for stable detections (same sign detected multiple times)\n",
        "                if len(detection_history) >= 5:\n",
        "                    all_recent_detections = []\n",
        "                    for det_list in list(detection_history)[-5:]:\n",
        "                        all_recent_detections.extend(det_list)\n",
        "\n",
        "                    if all_recent_detections:\n",
        "                        most_common = Counter(all_recent_detections).most_common(1)[0]\n",
        "                        if most_common[1] >= 3:  # Detected in at least 3 of last 5 frames\n",
        "                            stable_sign = most_common[0]\n",
        "                            if not stable_detections or stable_detections[-1] != stable_sign:\n",
        "                                stable_detections.append(stable_sign)\n",
        "                                print(f\" Detected: {stable_sign}\")\n",
        "\n",
        "            # Add info overlay\n",
        "            remaining = int(duration - (time.time() - start_time))\n",
        "            cv2.putText(frame, f\"Time: {remaining}s\", (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "            if stable_detections:\n",
        "                detected_text = ' '.join(stable_detections[-10:])  # Show last 10\n",
        "                cv2.putText(frame, f\"Detected: {detected_text}\", (10, 70),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "\n",
        "            # Show frame\n",
        "            cv2.imshow('ASL Real-Time Detection', frame)\n",
        "\n",
        "            # Exit on 'q' key\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                print(\"\\n Detection stopped by user\")\n",
        "                break\n",
        "\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        # Summary\n",
        "        print(f\"\\n Session Summary:\")\n",
        "        print(f\"   Duration: {time.time() - start_time:.1f} seconds\")\n",
        "        print(f\"   Frames processed: {frame_count}\")\n",
        "        print(f\"   Stable detections: {len(stable_detections)}\")\n",
        "\n",
        "        if stable_detections:\n",
        "            print(f\"\\n Detected sequence: {' '.join(stable_detections)}\")\n",
        "\n",
        "            # Capitalization options\n",
        "            letters = [s for s in stable_detections if s.isalpha()]\n",
        "            if letters:\n",
        "                text = ''.join(letters)\n",
        "                print(f\"\\n  Text options:\")\n",
        "                print(f\"   Lowercase: {text.lower()}\")\n",
        "                print(f\"   Uppercase: {text.upper()}\")\n",
        "                print(f\"   Title case: {text.title()}\")\n",
        "        else:\n",
        "            print(\"\\n No stable detections recorded\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\" OpenCV not available for webcam access\")\n",
        "    except Exception as e:\n",
        "        print(f\" Webcam detection error: {e}\")\n",
        "\n",
        "# Colab-specific message\n",
        "print(\" For Local Use:\")\n",
        "print(\"   1. Download this notebook\")\n",
        "print(\"   2. Run: real_time_asl_detection(30)\")\n",
        "print(\"   3. Point webcam at ASL signs\")\n",
        "print(\"   4. Press 'q' to quit\")\n",
        "\n",
        "print(\"\\n For Colab Alternative:\")\n",
        "print(\"   Use the image upload interface above to test individual images\")\n",
        "print(\"   Take photos with your phone/webcam and upload them\")\n",
        "\n",
        "# Create a simple test with sample detection\n",
        "def simulate_detection_demo():\n",
        "    \"\"\"Simulate real-time detection for demo purposes\"\"\"\n",
        "    print(\"\\n Simulating real-time detection...\")\n",
        "\n",
        "    # Simulate detection sequence\n",
        "    simulated_sequence = ['H', 'E', 'L', 'L', 'O']\n",
        "\n",
        "    for i, letter in enumerate(simulated_sequence):\n",
        "        print(f\"Frame {i+1}: Detected '{letter}' (confidence: 0.{85+i}%)\")\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    print(\"\\n Simulated detection complete!\")\n",
        "    print(f\"Detected word: {''.join(simulated_sequence)}\")\n",
        "    print(f\"Capitalization options:\")\n",
        "    text = ''.join(simulated_sequence)\n",
        "    print(f\"   Lowercase: {text.lower()}\")\n",
        "    print(f\"   Uppercase: {text.upper()}\")\n",
        "    print(f\"   Title case: {text.title()}\")\n",
        "\n",
        "print(\"\\n Try the simulation: simulate_detection_demo()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1SamuAkbppz",
        "outputId": "9f724371-8f58-4ffd-f831-b31296b8fd2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Real-Time ASL Detection Setup\n",
            "\n",
            " Note: Webcam access is limited in Google Colab.\n",
            "For full real-time detection, download this notebook and run locally.\n",
            "\n",
            " For Local Use:\n",
            "   1. Download this notebook\n",
            "   2. Run: real_time_asl_detection(30)\n",
            "   3. Point webcam at ASL signs\n",
            "   4. Press 'q' to quit\n",
            "\n",
            " For Colab Alternative:\n",
            "   Use the image upload interface above to test individual images\n",
            "   Take photos with your phone/webcam and upload them\n",
            "\n",
            " Try the simulation: simulate_detection_demo()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Run the simulation demo\n",
        "simulate_detection_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5m4n5DdbsZd",
        "outputId": "f749057e-ac6c-427b-fbc0-98fb4122467e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Simulating real-time detection...\n",
            "Frame 1: Detected 'H' (confidence: 0.85%)\n",
            "Frame 2: Detected 'E' (confidence: 0.86%)\n",
            "Frame 3: Detected 'L' (confidence: 0.87%)\n",
            "Frame 4: Detected 'L' (confidence: 0.88%)\n",
            "Frame 5: Detected 'O' (confidence: 0.89%)\n",
            "\n",
            " Simulated detection complete!\n",
            "Detected word: HELLO\n",
            "Capitalization options:\n",
            "   Lowercase: hello\n",
            "   Uppercase: HELLO\n",
            "   Title case: Hello\n"
          ]
        }
      ]
    }
  ]
}
